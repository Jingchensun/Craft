{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jingchen/promtsrc/output/base2new/train_base/caltech101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/caltech101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/caltech101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/dtd/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/dtd/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/dtd/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/eurosat/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/eurosat/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/eurosat/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/fgvc_aircraft/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/fgvc_aircraft/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/fgvc_aircraft/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/food101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/food101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/food101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/oxford_flowers/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/oxford_flowers/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/oxford_flowers/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/oxford_pets/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/oxford_pets/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/oxford_pets/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/stanford_cars/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/stanford_cars/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/stanford_cars/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/ucf101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/ucf101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "/home/jingchen/promtsrc/output/base2new/train_base/ucf101/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\n",
      "Time information saved to time_info.json.\n"
     ]
    }
   ],
   "source": [
    "# 1 save the dataset time to time_info_jason\n",
    "\n",
    "import re\n",
    "import json\n",
    "from datetime import timedelta\n",
    "\n",
    "# Create an empty dictionary to store time information for each dataset\n",
    "time_dict = {}\n",
    "\n",
    "for datasetname in ['caltech101', 'dtd', 'eurosat', 'fgvc_aircraft', 'food101', \n",
    "'oxford_flowers', 'oxford_pets', 'stanford_cars', 'ucf101']: #'sun397', 'imagenet'\n",
    "    dataset_info = {\"times\": [], \"seed_times\": []}\n",
    "    for seed in range(1, 4):  # Iterate over three seeds\n",
    "        seed_times = []\n",
    "        folder = f\"/home/jingchen/promtsrc/output/base2new/train_base/{datasetname}/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\"\n",
    "        print(folder)\n",
    "\n",
    "        file = f\"{folder}seed{seed}/log.txt\"  # Use seed1, seed2, seed3 for each dataset\n",
    "        \n",
    "        # Open the log.txt file to read its content\n",
    "        with open(file, \"r\") as file:\n",
    "            log_content = file.read()\n",
    "\n",
    "        elapsed_match = re.findall(r'Elapsed:\\s+([\\d:]+)', log_content)\n",
    "\n",
    "        if elapsed_match:\n",
    "            for elapsed_time_str in elapsed_match:\n",
    "                # Parse the elapsed time in the format \"1:58:54\" using timedelta\n",
    "                time_parts = elapsed_time_str.split(':')\n",
    "                elapsed_time = timedelta(hours=int(time_parts[0]), minutes=int(time_parts[1]), seconds=int(time_parts[2]))\n",
    "                seed_times.append(elapsed_time.total_seconds() / 60)  # Convert to minutes\n",
    "            dataset_info[\"seed_times\"].append(seed_times)\n",
    "            dataset_info[\"times\"].extend(seed_times)\n",
    "        else:\n",
    "            dataset_info[\"seed_times\"].append(\"N/A\")  # Set to \"N/A\" if no match is found\n",
    "            dataset_info[\"times\"].append(\"N/A\")\n",
    "\n",
    "    # Calculate average time across three seeds\n",
    "    dataset_avg_time = sum(dataset_info[\"times\"]) / len(dataset_info[\"times\"])\n",
    "    time_dict[datasetname] = {\"average_time\": dataset_avg_time, \"seed_times\": dataset_info[\"seed_times\"]}\n",
    "\n",
    "# Save the dictionary containing time information for all datasets as a JSON file\n",
    "with open(\"time_info.json\", \"w\") as json_file:\n",
    "    json.dump(time_dict, json_file, indent=4)\n",
    "\n",
    "print(\"Time information saved to time_info.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy information saved to accuracy.json.\n"
     ]
    }
   ],
   "source": [
    "# 2 evaulate on base2new dataset\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "dataset_info = []\n",
    "\n",
    "empty = 'sun397', 'imagenet'\n",
    "dataset1 = ['oxford_pets','oxford_flowers','fgvc_aircraft', 'dtd', 'eurosat', \n",
    "                    'stanford_cars', 'food101', 'caltech101', \n",
    "                    'ucf101', 'sun397', 'imagenet']\n",
    "dataset2 = ['oxford_pets','oxford_flowers','fgvc_aircraft', 'dtd', 'eurosat', \n",
    "                    'stanford_cars', 'food101', 'caltech101', \n",
    "                    'ucf101', 'sun397', 'imagenet',\n",
    "                    'imagenetv2', 'imagenet_sketch', 'imagenet_a', 'imagenet_r'] \n",
    "\n",
    "for datasetname in dataset2:\n",
    "    data_save = []  # Create a new list to store information for each dataset\n",
    "\n",
    "    # Promptscr Train\n",
    "    # folder = \"/home/jingchen/promtsrc/output/base2new/train_base/\" + datasetname + \"/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\"\n",
    "    # Promptscr novel test\n",
    "    # folder = \"/home/jingchen/promtsrc/output/base2new/test_new/\" + datasetname + \"/shots_16/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx/\"\n",
    "    # Promptscr cross dataset train\n",
    "    folder = \"/home/jingchen/promtsrc/output/imagenet/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx_cross_datasets-B128_16shots/\"\n",
    "    # Promptscr cross dataset test\n",
    "    # folder = \"/home/jingchen/promtsrc/output/evaluation/PromptSRC/vit_b16_c2_ep20_batch4_4+4ctx_cross_datasets-B128_16shots/\" + datasetname + '/' \n",
    "    # Maple Train\n",
    "    # folder = \"/home/jingchen/promtsrc/output/base2new/train_base/\" + datasetname + \"/shots_16/MaPLe/vit_b16_c2_ep5_batch4_2ctx/\"\n",
    "    # Maple Test\n",
    "    # folder = \"/home/jingchen/promtsrc/output/base2new/test_new/\" + datasetname + \"/shots_16/MaPLe/vit_b16_c2_ep5_batch4_2ctx/\"\n",
    "\n",
    "    accuracies = []  # Used to store accuracies for three seed loops\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        accuracy = {}  # Create a new dictionary to store dataset information\n",
    "        seed_folder = 'seed' + str(i)\n",
    "        file = os.path.join(folder, seed_folder, \"log.txt\")\n",
    "        if os.path.exists(file) == False:\n",
    "            break\n",
    "        # Copy the log.txt file to the destination folder\n",
    "        # destination_folder = os.path.join(os.path.expanduser(\"./\"), \"output_txt\", datasetname, \"mpt_cyclip_12\", seed_folder)\n",
    "        destination_folder = os.path.join(os.path.expanduser(\"./\"), \"output_txt\", datasetname, \"mpt-base\", seed_folder)\n",
    "        os.makedirs(destination_folder, exist_ok=True)  # 创建目标文件夹，如果不存在的话\n",
    "        shutil.copy2(file, destination_folder)  # 复制文件\n",
    "\n",
    "        # Open the log.txt file to read its content\n",
    "        with open(file, \"r\") as file:\n",
    "            log_content = file.read()\n",
    "\n",
    "        # Use regular expressions to find the starting position of \"Evaluate on the *test* set\"\n",
    "        start_pos = log_content.find(\"Evaluate on the *test* set\")\n",
    "\n",
    "        if start_pos != -1:\n",
    "            # Find \"accuracy: xxx.xxx%\" after \"Evaluate on the *test* set\"\n",
    "            accuracy_match = re.search(r'accuracy:\\s+(\\d+\\.\\d+%)', log_content[start_pos:])\n",
    "            \n",
    "            if accuracy_match:\n",
    "                accuracy_value = float(accuracy_match.group(1)[:-1])  # Remove the percentage sign and convert to float\n",
    "                accuracies.append(accuracy_value)\n",
    "            else:\n",
    "                accuracy_value = \"N/A\"  # Set to \"N/A\" if no match is found\n",
    "\n",
    "            elapsed_match = re.search(r'Elapsed:\\s+([\\d:]+)', log_content[start_pos:])\n",
    "\n",
    "            if elapsed_match:\n",
    "                elapsed_time_str = elapsed_match.group(1)\n",
    "                # Parse the elapsed time in the format \"1:58:54\" using datetime\n",
    "                time_parts = elapsed_time_str.split(':')\n",
    "                elapsed_time = timedelta(hours=int(time_parts[0]), minutes=int(time_parts[1]), seconds=int(time_parts[2]))\n",
    "                accuracy['time'] = str(elapsed_time)\n",
    "            else:\n",
    "                accuracy['time'] = \"N/A\"  # Set to \"N/A\" if no match is found\n",
    "\n",
    "            # Create a dictionary containing accuracy and time information\n",
    "            accuracy['seed'] = seed_folder\n",
    "            accuracy['accuracy'] = accuracy_value\n",
    "\n",
    "            # Add the current dataset's information to the list\n",
    "            data_save.append(accuracy)\n",
    "\n",
    "    # Calculate mean and variance\n",
    "    mean_accuracy = round(np.mean(accuracies), 3)\n",
    "    variance_accuracy = round(np.var(accuracies), 3)\n",
    "\n",
    "    # Add mean and variance to dataset information\n",
    "    dataset_info.append({\n",
    "        datasetname: {\n",
    "            \"data\": data_save,\n",
    "            \"mean\": mean_accuracy,\n",
    "            \"var\": variance_accuracy\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Save the list containing information for two datasets as a JSON file\n",
    "with open(\"accuracy.json\", \"w\") as json_file:\n",
    "    json.dump(dataset_info, json_file, indent=4)\n",
    "\n",
    "print(\"Accuracy information saved to accuracy.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load data from JSON file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 7\u001b[0m     dataset_info \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a dictionary to store accuracy lists for each seed\u001b[39;00m\n\u001b[1;32m     10\u001b[0m seed_accuracies \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/clipood/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clipood/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/clipood/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/clipood/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# 3 calculate the mean Accuracy\n",
    "\n",
    "import json\n",
    "\n",
    "# Load data from JSON file\n",
    "with open(\"accuracy.json\", \"r\") as file:\n",
    "    dataset_info = json.load(file)\n",
    "\n",
    "# Create a dictionary to store accuracy lists for each seed\n",
    "seed_accuracies = {}\n",
    "\n",
    "# Iterate over each dataset\n",
    "for dataset in dataset_info:\n",
    "    dataset_name = list(dataset.keys())[0]  # Dataset name\n",
    "    dataset_data = dataset[dataset_name][\"data\"]  # Accuracy data of the dataset\n",
    "\n",
    "    # Iterate over accuracy data of the dataset\n",
    "    for data in dataset_data:\n",
    "        seed = data[\"seed\"]  # Seed\n",
    "        accuracy = data[\"accuracy\"]  # Accuracy\n",
    "\n",
    "        # If the seed is not in seed_accuracies, create a new key-value pair\n",
    "        if seed not in seed_accuracies:\n",
    "            seed_accuracies[seed] = []\n",
    "\n",
    "        # Add accuracy to the list of the current seed\n",
    "        seed_accuracies[seed].append(accuracy)\n",
    "\n",
    "# Calculate the mean accuracy for each seed and print output\n",
    "for seed, accuracies in seed_accuracies.items():\n",
    "    mean_accuracy = round(sum(accuracies) / len(accuracies), 3)\n",
    "    print(f\"Seed {seed}: Mean Accuracy = {mean_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
